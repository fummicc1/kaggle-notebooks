{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-11-23T06:55:23.370371Z","iopub.status.busy":"2022-11-23T06:55:23.37001Z","iopub.status.idle":"2022-11-23T06:55:23.377309Z","shell.execute_reply":"2022-11-23T06:55:23.376345Z","shell.execute_reply.started":"2022-11-23T06:55:23.37034Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:23.380301Z","iopub.status.busy":"2022-11-23T06:55:23.379574Z","iopub.status.idle":"2022-11-23T06:55:23.388855Z","shell.execute_reply":"2022-11-23T06:55:23.387772Z","shell.execute_reply.started":"2022-11-23T06:55:23.380264Z"},"trusted":true},"outputs":[],"source":["# !pip install --upgrade torch torchvision"]},{"cell_type":"markdown","metadata":{},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:23.39106Z","iopub.status.busy":"2022-11-23T06:55:23.39042Z","iopub.status.idle":"2022-11-23T06:55:23.401175Z","shell.execute_reply":"2022-11-23T06:55:23.400099Z","shell.execute_reply.started":"2022-11-23T06:55:23.391026Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","from torchvision import transforms\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from PIL import Image\n","from typing import Dict, List, Tuple\n","from tqdm import tqdm\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:23.404424Z","iopub.status.busy":"2022-11-23T06:55:23.403789Z","iopub.status.idle":"2022-11-23T06:55:23.413725Z","shell.execute_reply":"2022-11-23T06:55:23.412695Z","shell.execute_reply.started":"2022-11-23T06:55:23.404389Z"},"trusted":true},"outputs":[],"source":["class Config:\n","    base_input_path = \"/workspace/kaggle-notebooks/\"\n","    batch_size = 32\n","    num_workers = 4\n","    n_epochs = 5\n","    lr = 1e-4\n","    \n","    def __init__(self):\n","        pass\n","    \n","config = Config()\n","\n","def convert_num2label(num: int) -> str:\n","    return {\n","        \"0\": \"Cassava Bacterial Blight (CBB)\",\n","        \"1\": \"Cassava Brown Streak Disease (CBSD)\",\n","        \"2\": \"Cassava Green Mottle (CGM)\",\n","        \"3\": \"Cassava Mosaic Disease (CMD)\",\n","        \"4\": \"Healthy\",\n","    }[num]\n","\n","\n","def class2dict(f) -> Dict:\n","    ans = dict()\n","    for name in dir(f):\n","        if name.startswith(\"__\"):\n","            continue\n","        if not _is_primitive(getattr(f, name)):\n","            ans[name] = class2dict(getattr(f, name))\n","        else:\n","            ans[name] = getattr(f, name)\n","    return ans\n","\n","\n","def _is_primitive(value) -> bool:\n","    primitive = (int, str, bool, float, List, Dict)\n","    return type(value) in primitive"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:23.416039Z","iopub.status.busy":"2022-11-23T06:55:23.41534Z","iopub.status.idle":"2022-11-23T06:55:23.710734Z","shell.execute_reply":"2022-11-23T06:55:23.709657Z","shell.execute_reply.started":"2022-11-23T06:55:23.415966Z"},"trusted":true},"outputs":[],"source":["train_path = os.path.join(config.base_input_path, \"train.csv\")\n","train_img_dir_path = os.path.join(config.base_input_path, \"train_images\")\n","train_df = pd.read_csv(train_path)\n","train_df.label.value_counts().plot(kind=\"bar\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:23.713747Z","iopub.status.busy":"2022-11-23T06:55:23.713156Z","iopub.status.idle":"2022-11-23T06:55:23.721862Z","shell.execute_reply":"2022-11-23T06:55:23.720888Z","shell.execute_reply.started":"2022-11-23T06:55:23.713711Z"},"trusted":true},"outputs":[],"source":["class CassavaDataset(Dataset):\n","    def __init__(self, annotation_path: str, img_dir_path: str, img_transforms: transforms.Compose):\n","        self.annotation_path = annotation_path\n","        self.annotation_data = pd.read_csv(annotation_path)\n","        self.img_dir_path = img_dir_path\n","        self.img_transforms = img_transforms\n","        \n","    def __len__(self) -> int:\n","        return len(self.annotation_data)\n","    \n","    def __getitem__(self, index: int):\n","        data = self.annotation_data.iloc[index, :]\n","        image_id = data[\"image_id\"]\n","        label = data[\"label\"]        \n","        image_path = os.path.join(self.img_dir_path, image_id)        \n","        img = Image.open(image_path).convert(\"RGB\")\n","        if self.img_transforms:\n","            img = self.img_transforms(img)\n","        label = torch.nn.functional.one_hot(torch.tensor([label]), num_classes=5)\n","        label = torch.squeeze(label, dim=0).float()\n","        return img, image_id, label"]},{"cell_type":"markdown","metadata":{},"source":["## Network"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:23.762672Z","iopub.status.busy":"2022-11-23T06:55:23.76233Z","iopub.status.idle":"2022-11-23T06:55:23.773118Z","shell.execute_reply":"2022-11-23T06:55:23.772183Z","shell.execute_reply.started":"2022-11-23T06:55:23.762639Z"},"trusted":true},"outputs":[],"source":["from torchvision.models import resnet18, ResNet18_Weights\n","\n","\n","class CassavaNetwork(nn.Module):\n","    def __init__(self, input_dim: int = 3, output_dim: int = 5):\n","        super().__init__()\n","        self.base_model = resnet18(pretrained=ResNet18_Weights.DEFAULT)\n","        self.base_model.conv1 = nn.Conv2d(\n","            input_dim,\n","            64,\n","            kernel_size=(7, 7),\n","            stride=(2, 2), \n","            padding=(3, 3), \n","            bias=False\n","        )\n","        self.base_model.fc = nn.Linear(in_features=512, out_features=output_dim, bias=True)\n","    \n","    def forward(self, img: torch.Tensor) -> torch.Tensor:\n","        return self.base_model(img)"]},{"cell_type":"markdown","metadata":{},"source":["## Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:23.777241Z","iopub.status.busy":"2022-11-23T06:55:23.776951Z","iopub.status.idle":"2022-11-23T06:55:23.79177Z","shell.execute_reply":"2022-11-23T06:55:23.790919Z","shell.execute_reply.started":"2022-11-23T06:55:23.777217Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from typing import Optional\n","from torch.cuda.amp.grad_scaler import GradScaler\n","from torch.cuda.amp.autocast_mode import autocast\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torch\n","\n","import sys\n","import os\n","\n","\n","class TrainerOutput:\n","    loss: float\n","\n","    def __init__(self, loss: float):\n","        self.loss = loss\n","\n","    @property\n","    def score(self) -> float:\n","        return self.loss\n","\n","\n","class Trainer:\n","    model: nn.Module\n","    optimizer: optim.Optimizer\n","    lr_scheduler: optim.lr_scheduler._LRScheduler\n","    loss_function: nn.CrossEntropyLoss\n","    dataloader: DataLoader\n","    scaler: Optional[GradScaler]\n","\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        optimizer: optim.Optimizer,\n","        lr_scheduler: optim.lr_scheduler._LRScheduler,\n","        loss_function: nn.CrossEntropyLoss,\n","        dataloader: DataLoader,\n","        scaler: Optional[GradScaler] = None,\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.lr_scheduler = lr_scheduler\n","        self.loss_function = loss_function\n","        self.dataloader = dataloader\n","        self.scaler = scaler\n","\n","    def advance(self, verbose: bool = False) -> TrainerOutput:\n","        scaler = None\n","        if self.scaler:\n","            scaler = self.scaler\n","        self.model = self.model.train()\n","        GPU_DEVICE = torch.device(\"cuda\")\n","        epoch_loss = 0\n","        with autocast(enabled=True):\n","            with torch.enable_grad():\n","                for batch in tqdm(self.dataloader):\n","                    if len(batch) == 3:\n","                        imgs, ids, labels = batch\n","                    elif len(batch) == 2:\n","                        imgs, labels = batch\n","                    else:\n","                        continue\n","                    self.optimizer.zero_grad()\n","                    imgs = imgs.to(GPU_DEVICE)\n","                    labels = labels.to(GPU_DEVICE)\n","                    out: torch.Tensor = self.model(imgs)\n","                    out = out.float()\n","                    if verbose:\n","                        print(\"out-shape\", out.shape)\n","                        print(\"out\", out)                        \n","                    if verbose:\n","                        print(\"labels\", labels)\n","                    loss = self.loss_function(out, labels)\n","                    if verbose:\n","                        print(\"loss\", loss)\n","                    if scaler is not None:\n","                        scaler.scale(loss).backward()\n","                    else:\n","                        loss.backward()\n","                    epoch_loss += loss.item()\n","                    if scaler is not None:\n","                        scaler.step(self.optimizer)\n","                        scaler.update()\n","                    else:\n","                        self.optimizer.step()\n","                self.lr_scheduler.step()\n","        loss = epoch_loss / (len(self.dataloader))\n","        return TrainerOutput(loss=loss)"]},{"cell_type":"markdown","metadata":{},"source":["## Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:23.793843Z","iopub.status.busy":"2022-11-23T06:55:23.79326Z","iopub.status.idle":"2022-11-23T06:55:23.817639Z","shell.execute_reply":"2022-11-23T06:55:23.816715Z","shell.execute_reply.started":"2022-11-23T06:55:23.793798Z"},"trusted":true},"outputs":[],"source":["from typing import Callable, Dict, List, Tuple, Union, Optional\n","from typing_extensions import Self\n","import numpy as np\n","from torch import Tensor\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","\n","import sys\n","import os\n","\n","\n","class ClassifierOutput:\n","    move_to_full_nn_img_ids: List[str]\n","    count: int\n","    recall: float\n","    precision: float\n","    f_value: float\n","    acc: float\n","    loss: float\n","    df: pd.DataFrame = pd.DataFrame()\n","\n","    def __init__(\n","        self,\n","        count: int,\n","        recall: float,\n","        precision: float,\n","        acc: float,\n","        loss: float,\n","        move_to_full_nn_img_ids=[],\n","    ):\n","        self.count = count\n","        self.recall = recall\n","        self.precision = precision\n","        if recall + precision == 0:\n","            self.f_value = 0\n","        else:\n","            self.f_value = (2 * recall * precision) / (recall + precision)\n","        self.acc = acc\n","        self.loss = loss\n","        self.move_to_full_nn_img_ids = move_to_full_nn_img_ids\n","\n","    @property\n","    def score(self) -> float:\n","        return self.acc\n","\n","\n","class ClassifierTrainInput:\n","    def __init__(self):\n","        pass\n","\n","class ClassifierTestInput:\n","    def __init__(self):\n","        pass\n","\n","class Classifier:\n","\n","    model: nn.Module\n","    activate_function: nn.Softmax\n","    loss_function: Optional[nn.CrossEntropyLoss]\n","    c_high: float\n","    c_low: float\n","    dataloader: DataLoader\n","    phase: str\n","    phase_input: Union[ClassifierTrainInput, ClassifierTestInput]\n","    on_classify: Optional[Callable]\n","\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        activate_function: nn.Softmax,\n","        dataloader: DataLoader,\n","        phase: str,\n","        phase_input: Union[ClassifierTrainInput, ClassifierTestInput],\n","        loss_function: Optional[nn.CrossEntropyLoss] = None,\n","        on_classify: Optional[Callable] = None,\n","    ):\n","        self.model = model\n","        self.activate_function = activate_function\n","        self.loss_function = loss_function\n","        self.dataloader = dataloader\n","        self.phase = phase\n","        self.phase_input = phase_input\n","        self.on_classify = on_classify\n","\n","    def infer(\n","        self, verbose: bool = False, handle_all: bool = False\n","    ) -> ClassifierOutput:\n","        net = self.model\n","        loader = self.dataloader\n","        loss_function = self.loss_function\n","        count = 0\n","        recall = 0\n","        precision = 0\n","        correct = 0\n","        TP = 0\n","        FP = 0\n","        FN = 0\n","        GPU_DEVICE = torch.device(\"cuda\")\n","        called = False\n","        net = net.eval()\n","        epoch_loss = 0\n","        label_df = pd.DataFrame()\n","        with torch.no_grad():\n","            for batch in tqdm(loader):\n","                if len(batch) == 3:\n","                    imgs, ids, labels = batch\n","                elif len(batch) == 2:\n","                    imgs, labels = batch\n","                else:\n","                    continue\n","                imgs = imgs.to(GPU_DEVICE)\n","                labels = labels.to(GPU_DEVICE)                \n","                outputs = net(imgs)\n","                if loss_function:\n","                    loss = loss_function(outputs, labels)\n","                    epoch_loss += loss.item()\n","                outputs = self.activate_function(outputs)\n","                if verbose:\n","                    print(\"output\", outputs[:10])\n","                _, pred_indexes = torch.max(outputs, dim=1)\n","                pred_indexes: Tensor = pred_indexes\n","                if verbose:\n","                    print(f\"{self.phase}_predicted_indexes\", pred_indexes)\n","                    print(f\"{self.phase}_labels\", labels)\n","                if not called and self.on_classify is not None:\n","                    if not handle_all:\n","                        called = True\n","                    self.on_classify(imgs, pred_indexes)\n","                labels = torch.tensor(list(map(lambda nums: (nums==1).nonzero().item(), labels))).to(GPU_DEVICE)\n","                count += labels.shape[0]\n","                batch_df = pd.DataFrame()\n","                batch_df[\"image_id\"] = ids\n","                batch_df[\"label\"] = pd.Series(labels.detach().cpu().numpy())\n","                if len(label_df) == 0:\n","                    label_df = batch_df\n","                else:\n","                    label_df = pd.concat([label_df, batch_df])                    \n","                correct += int(torch.where(pred_indexes == labels, 1.0, 0.0).sum())\n","            acc = correct / count\n","            epoch_loss = epoch_loss / (len(loader))\n","            ret = ClassifierOutput(\n","                count=count,\n","                recall=recall,\n","                precision=precision,\n","                acc=acc,\n","                loss=epoch_loss,\n","            )\n","            label_df.reset_index(drop=True, inplace=True)\n","            ret.df = label_df\n","            return ret"]},{"cell_type":"markdown","metadata":{},"source":["## Run"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T06:55:24.070759Z","iopub.status.busy":"2022-11-23T06:55:24.070503Z","iopub.status.idle":"2022-11-23T06:55:24.07785Z","shell.execute_reply":"2022-11-23T06:55:24.077024Z","shell.execute_reply.started":"2022-11-23T06:55:24.070735Z"},"trusted":true},"outputs":[],"source":["import torch.optim as optim\n","from sklearn.model_selection import KFold\n","from torch.utils.data.dataset import Subset\n","import wandb\n","\n","index = 3\n","name = f\"run-{index}\"\n","notes = \"\"\n","\n","wandb.init(\n","    project=\"kaggle-cassava\",\n","    name=name,\n","    notes=notes,\n","    config=config,\n",")\n","\n","data_path = os.path.join(config.base_input_path, \"train.csv\")\n","data_img_dir_path = os.path.join(config.base_input_path, \"train_images\")\n","df = pd.read_csv(train_path)\n","\n","df.label.value_counts().plot(kind=\"bar\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def set_seed(seed):\n","    np.random.seed(seed)\n","    random_state = np.random.RandomState(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    return random_state\n","\n","set_seed(42)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":[]}],"source":["\n","k_fold = KFold(n_splits=2)\n","train_dataset = CassavaDataset(\n","    annotation_path=data_path,\n","    img_dir_path=data_img_dir_path,\n","    img_transforms=transforms.Compose([\n","        transforms.ToTensor(),    \n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    ]),\n",")\n","val_dataset = CassavaDataset(\n","    annotation_path=data_path,\n","    img_dir_path=data_img_dir_path,\n","    img_transforms=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    ]),\n",")\n","\n","for fold, (train_index, val_index) in enumerate(k_fold.split(df)):\n","    train_subset = Subset(train_dataset, train_index)\n","    train_dataloader = DataLoader(\n","        train_subset,\n","        batch_size=config.batch_size,\n","        num_workers=config.num_workers,\n","        shuffle=True,\n","    )\n","    val_subset = Subset(val_dataset, val_index)\n","    val_dataloader = DataLoader(\n","        val_subset,\n","        batch_size=config.batch_size,\n","        num_workers=config.num_workers,\n","    )\n","    model = CassavaNetwork()\n","    model = model.to(torch.device(\"cuda\"))\n","    model = nn.DataParallel(model)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n","    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n","    loss_function = nn.CrossEntropyLoss()\n","\n","    activate_function = nn.Softmax(dim=1)\n","\n","    trainer = Trainer(\n","        model,\n","        optimizer,\n","        scheduler,\n","        loss_function,\n","        train_dataloader,\n","    )\n","    classifier = Classifier(\n","        model,\n","        activate_function,\n","        train_dataloader,\n","        phase=\"train\",\n","        phase_input=ClassifierTrainInput(),\n","    )\n","\n","    val_classifier = Classifier(\n","        model,\n","        activate_function,\n","        val_dataloader,\n","        phase=\"test\",\n","        phase_input=ClassifierTestInput(),\n","    )\n","\n","\n","    for epoch in tqdm(range(config.n_epochs)):\n","        epoch += 1\n","        train_out = trainer.advance()\n","        print(f\"epoch: {epoch}, train loss: {train_out.loss}\")\n","        train_infer_out = classifier.infer()\n","        print(f\"epoch: {epoch}, train acc: {train_infer_out.acc}\")\n","        val_infer_out = val_classifier.infer()\n","        print(f\"epoch: {epoch}, val acc: {val_infer_out.acc}\")\n","        wandb.log({\n","            \"epoch\": epoch,\n","            \"train-loss\": train_out.loss,\n","            \"train-acc\": train_infer_out.acc,\n","            \"val-acc\": val_infer_out.acc,\n","        })\n","    break\n","\n","# Create submissions\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_data_path = os.path.join(config.base_input_path, \"sample_submission.csv\")\n","test_data_img_dir_path = os.path.join(config.base_input_path, \"test_images\")\n","test_dataset = CassavaDataset(\n","    annotation_path=test_data_path,\n","    img_dir_path=test_data_img_dir_path,\n","    img_transforms=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    ]),\n",")\n","\n","test_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size=config.batch_size,\n","    num_workers=config.num_workers,\n",")\n","\n","test_classifier = Classifier(\n","    model,\n","    activate_function,\n","    test_dataloader,\n","    phase=\"test\",\n","    phase_input=ClassifierTrainInput(),\n",")\n","\n","out = test_classifier.infer()\n","out.df.to_csv(\"submissions.csv\")"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"91f5f513b45197eec3161b585827a1921a9dc7ec37470ec30d3f76f96edefaef"}}},"nbformat":4,"nbformat_minor":4}
