{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-23T06:55:23.37001Z","iopub.execute_input":"2022-11-23T06:55:23.370371Z","iopub.status.idle":"2022-11-23T06:55:23.377309Z","shell.execute_reply.started":"2022-11-23T06:55:23.37034Z","shell.execute_reply":"2022-11-23T06:55:23.376345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade torch torchvision","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.379574Z","iopub.execute_input":"2022-11-23T06:55:23.380301Z","iopub.status.idle":"2022-11-23T06:55:23.388855Z","shell.execute_reply.started":"2022-11-23T06:55:23.380264Z","shell.execute_reply":"2022-11-23T06:55:23.387772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nfrom torchvision import transforms\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nfrom typing import Dict, List, Tuple\nfrom tqdm import tqdm\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.39042Z","iopub.execute_input":"2022-11-23T06:55:23.39106Z","iopub.status.idle":"2022-11-23T06:55:23.401175Z","shell.execute_reply.started":"2022-11-23T06:55:23.391026Z","shell.execute_reply":"2022-11-23T06:55:23.400099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    base_input_path = \"/kaggle/input/cassava-leaf-disease-classification\"\n    \n    batch_size = 16\n    num_workers = 2\n    n_epochs = 10\n    lr = 1e-3\n    \n    def __init__(self):\n        pass\n    \nconfig = Config()\n\ndef convert_num2label(num: int) -> str:\n    return {\n        \"0\": \"Cassava Bacterial Blight (CBB)\",\n        \"1\": \"Cassava Brown Streak Disease (CBSD)\",\n        \"2\": \"Cassava Green Mottle (CGM)\",\n        \"3\": \"Cassava Mosaic Disease (CMD)\",\n        \"4\": \"Healthy\",\n    }[num]\n\n\ndef class2dict(f) -> Dict:\n    ans = dict()\n    for name in dir(f):\n        if name.startswith(\"__\"):\n            continue\n        if not _is_primitive(getattr(f, name)):\n            ans[name] = class2dict(getattr(f, name))\n        else:\n            ans[name] = getattr(f, name)\n    return ans\n\n\ndef _is_primitive(value) -> bool:\n    primitive = (int, str, bool, float, List, Dict)\n    return type(value) in primitive","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.403789Z","iopub.execute_input":"2022-11-23T06:55:23.404424Z","iopub.status.idle":"2022-11-23T06:55:23.413725Z","shell.execute_reply.started":"2022-11-23T06:55:23.404389Z","shell.execute_reply":"2022-11-23T06:55:23.412695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = os.path.join(config.base_input_path, \"train.csv\")\ntrain_img_dir_path = os.path.join(config.base_input_path, \"train_images\")\ntrain_df = pd.read_csv(train_path)\ntrain_df.label.value_counts().plot(kind=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.41534Z","iopub.execute_input":"2022-11-23T06:55:23.416039Z","iopub.status.idle":"2022-11-23T06:55:23.710734Z","shell.execute_reply.started":"2022-11-23T06:55:23.415966Z","shell.execute_reply":"2022-11-23T06:55:23.709657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(self, annotation_path: str, img_dir_path: str, img_transforms: transforms.Compose):\n        self.annotation_path = annotation_path\n        self.annotation_data = pd.read_csv(annotation_path)\n        self.img_dir_path = img_dir_path\n        self.img_transforms = img_transforms\n        \n    def __len__(self) -> int:\n        return len(self.annotation_data)\n    \n    def __getitem__(self, index: int):\n        data = self.annotation_data.iloc[index, :]\n        image_id = data[\"image_id\"]\n        label = data[\"label\"]        \n        image_path = os.path.join(self.img_dir_path, image_id)        \n        img = Image.open(image_path).convert(\"RGB\")\n        if self.img_transforms:\n            img = self.img_transforms(img)\n        label = torch.nn.functional.one_hot(torch.tensor([label]), num_classes=5)\n        label = torch.squeeze(label, dim=0).float()\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.713156Z","iopub.execute_input":"2022-11-23T06:55:23.713747Z","iopub.status.idle":"2022-11-23T06:55:23.721862Z","shell.execute_reply.started":"2022-11-23T06:55:23.713711Z","shell.execute_reply":"2022-11-23T06:55:23.720888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets = CassavaDataset(\n    annotation_path=train_path,\n    img_dir_path=train_img_dir_path,\n    img_transforms=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n    ])\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.723519Z","iopub.execute_input":"2022-11-23T06:55:23.723953Z","iopub.status.idle":"2022-11-23T06:55:23.753288Z","shell.execute_reply.started":"2022-11-23T06:55:23.723841Z","shell.execute_reply":"2022-11-23T06:55:23.752468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(\n    datasets,\n    batch_size=config.batch_size,\n    shuffle=True,\n    num_workers=config.num_workers\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.755821Z","iopub.execute_input":"2022-11-23T06:55:23.756424Z","iopub.status.idle":"2022-11-23T06:55:23.76094Z","shell.execute_reply.started":"2022-11-23T06:55:23.756387Z","shell.execute_reply":"2022-11-23T06:55:23.760127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Network","metadata":{}},{"cell_type":"code","source":"from torchvision.models import resnet18\n\n\nclass CassavaNetwork(nn.Module):\n    def __init__(self, input_dim: int = 3, output_dim: int = 5):\n        super().__init__()\n        self.base_model = resnet18(pretrained=True)\n        self.base_model.conv1 = nn.Conv2d(\n            input_dim,\n            64,\n            kernel_size=(7, 7),\n            stride=(2, 2), \n            padding=(3, 3), \n            bias=False\n        )\n        self.base_model.fc = nn.Linear(in_features=512, out_features=output_dim, bias=True)\n    \n    def forward(self, img: torch.Tensor) -> torch.Tensor:\n        return self.base_model(img)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.76233Z","iopub.execute_input":"2022-11-23T06:55:23.762672Z","iopub.status.idle":"2022-11-23T06:55:23.773118Z","shell.execute_reply.started":"2022-11-23T06:55:23.762639Z","shell.execute_reply":"2022-11-23T06:55:23.772183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainer","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom typing import Optional\nfrom torch.cuda.amp.grad_scaler import GradScaler\nfrom torch.cuda.amp.autocast_mode import autocast\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torch\n\nimport sys\nimport os\n\n\nclass TrainerOutput:\n    loss: float\n\n    def __init__(self, loss: float):\n        self.loss = loss\n\n    @property\n    def score(self) -> float:\n        return self.loss\n\n\nclass Trainer:\n    model: nn.Module\n    optimizer: optim.Optimizer\n    lr_scheduler: optim.lr_scheduler._LRScheduler\n    loss_function: nn.CrossEntropyLoss\n    dataloader: DataLoader\n    scaler: Optional[GradScaler]\n\n    def __init__(\n        self,\n        model: nn.Module,\n        optimizer: optim.Optimizer,\n        lr_scheduler: optim.lr_scheduler._LRScheduler,\n        loss_function: nn.CrossEntropyLoss,\n        dataloader: DataLoader,\n        scaler: Optional[GradScaler] = None,\n    ):\n        self.model = model\n        self.optimizer = optimizer\n        self.lr_scheduler = lr_scheduler\n        self.loss_function = loss_function\n        self.dataloader = dataloader\n        self.scaler = scaler\n\n    def advance(self, verbose: bool = False) -> TrainerOutput:\n        scaler = None\n        if self.scaler:\n            scaler = self.scaler\n        self.model = self.model.train()\n        GPU_DEVICE = torch.device(\"cuda\")\n        epoch_loss = 0\n        with autocast(enabled=True):\n            with torch.enable_grad():\n                for batch in tqdm(self.dataloader):\n                    if len(batch) == 3:\n                        imgs, _, labels = batch\n                    elif len(batch) == 2:\n                        imgs, labels = batch\n                    else:\n                        continue\n                    self.optimizer.zero_grad()\n                    imgs = imgs.to(GPU_DEVICE)\n                    labels = labels.to(GPU_DEVICE)\n                    out: torch.Tensor = self.model(imgs)\n                    out = out.float()\n                    if verbose:\n                        print(\"out-shape\", out.shape)\n                        print(\"out\", out)                        \n                    if verbose:\n                        print(\"labels\", labels)\n                    loss = self.loss_function(out, labels)\n                    if verbose:\n                        print(\"loss\", loss)\n                    if scaler is not None:\n                        scaler.scale(loss).backward()\n                    else:\n                        loss.backward()\n                    epoch_loss += loss.item()\n                    if scaler is not None:\n                        scaler.step(self.optimizer)\n                        scaler.update()\n                    else:\n                        self.optimizer.step()\n                self.lr_scheduler.step()\n        loss = epoch_loss / (len(self.dataloader))\n        return TrainerOutput(loss=loss)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.776951Z","iopub.execute_input":"2022-11-23T06:55:23.777241Z","iopub.status.idle":"2022-11-23T06:55:23.79177Z","shell.execute_reply.started":"2022-11-23T06:55:23.777217Z","shell.execute_reply":"2022-11-23T06:55:23.790919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classifier","metadata":{}},{"cell_type":"code","source":"from typing import Callable, Dict, List, Tuple, Union, Optional\nfrom typing_extensions import Self\nimport numpy as np\nfrom torch import Tensor\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nimport sys\nimport os\n\n\nclass ClassifierOutput:\n    move_to_full_nn_img_ids: List[str]\n    count: int\n    recall: float\n    precision: float\n    f_value: float\n    acc: float\n    loss: float\n\n    def __init__(\n        self,\n        count: int,\n        recall: float,\n        precision: float,\n        acc: float,\n        loss: float,\n        move_to_full_nn_img_ids=[],\n    ):\n        self.count = count\n        self.recall = recall\n        self.precision = precision\n        if recall + precision == 0:\n            self.f_value = 0\n        else:\n            self.f_value = (2 * recall * precision) / (recall + precision)\n        self.acc = acc\n        self.loss = loss\n        self.move_to_full_nn_img_ids = move_to_full_nn_img_ids\n\n    @property\n    def score(self) -> float:\n        return self.acc\n\n\nclass ClassifierTrainInput:\n    def __init__(self):\n        pass\n\nclass ClassifierTestInput:\n    def __init__(self):\n        pass\n\nclass Classifier:\n\n    model: nn.Module\n    activate_function: nn.Softmax\n    loss_function: Optional[nn.CrossEntropyLoss]\n    c_high: float\n    c_low: float\n    dataloader: DataLoader\n    phase: str\n    phase_input: Union[ClassifierTrainInput, ClassifierTestInput]\n    on_classify: Optional[Callable]\n\n    def __init__(\n        self,\n        model: nn.Module,\n        activate_function: nn.Softmax,\n        dataloader: DataLoader,\n        phase: str,\n        phase_input: Union[ClassifierTrainInput, ClassifierTestInput],\n        loss_function: Optional[nn.CrossEntropyLoss] = None,\n        on_classify: Optional[Callable] = None,\n    ):\n        self.model = model\n        self.activate_function = activate_function\n        self.loss_function = loss_function\n        self.dataloader = dataloader\n        self.phase = phase\n        self.phase_input = phase_input\n        self.on_classify = on_classify\n\n    def infer(\n        self, verbose: bool = False, handle_all: bool = False\n    ) -> ClassifierOutput:\n        net = self.model\n        loader = self.dataloader\n        loss_function = self.loss_function\n        count = 0\n        recall = 0\n        precision = 0\n        correct = 0\n        positives = 0\n        TP = 0\n        FP = 0\n        GPU_DEVICE = torch.device(\"cuda\")\n        called = False\n        net = net.eval()\n        epoch_loss = 0\n        with torch.no_grad():\n            for batch in tqdm(loader):\n                if len(batch) == 3:\n                    imgs, _, labels = batch\n                elif len(batch) == 2:\n                    imgs, labels = batch\n                else:\n                    continue\n                imgs = imgs.to(GPU_DEVICE)\n                labels = labels.to(GPU_DEVICE)\n                outputs = net(imgs)\n                if loss_function:\n                    loss = loss_function(outputs, labels)\n                    epoch_loss += loss.item()\n                outputs = self.activate_function(outputs)\n                if verbose:\n                    print(\"output\", outputs[:10])\n                _, predicted_indexes = torch.max(dim=1, input=outputs)\n                if verbose:\n                    print(f\"{self.phase}_predicted_indexes\", predicted_indexes[:10])\n                if not called and self.on_classify is not None:\n                    if not handle_all:\n                        called = True\n                    self.on_classify(imgs, predicted_indexes)\n                count += labels.shape[0]\n                for i in range(len(labels)):\n                    if labels[i] == 1:\n                        # has_object\n                        positives += 1\n                        if predicted_indexes[i].item():\n                            TP += 1\n                    else:\n                        # background\n                        if predicted_indexes[i].item():\n                            FP += 1\n                correct += int(torch.where(predicted_indexes == labels, 1.0, 0.0).sum())\n            predicted_positives = TP + FP\n            if predicted_positives == 0:\n                precision = 0.0\n            else:\n                precision = TP / predicted_positives\n            if positives == 0:\n                recall = 0\n            else:\n                recall = TP / positives\n            acc = correct / count\n            epoch_loss = epoch_loss / (len(loader))\n            ret = ClassifierOutput(\n                count=count,\n                recall=recall,\n                precision=precision,\n                acc=acc,\n                loss=epoch_loss,\n            )\n            return ret","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.79326Z","iopub.execute_input":"2022-11-23T06:55:23.793843Z","iopub.status.idle":"2022-11-23T06:55:23.817639Z","shell.execute_reply.started":"2022-11-23T06:55:23.793798Z","shell.execute_reply":"2022-11-23T06:55:23.816715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run","metadata":{}},{"cell_type":"code","source":"train_path = os.path.join(config.base_input_path, \"train.csv\")\ntrain_img_dir_path = os.path.join(config.base_input_path, \"train_images\")\ntrain_df = pd.read_csv(train_path)\ntrain_df.label.value_counts().plot(kind=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:23.819758Z","iopub.execute_input":"2022-11-23T06:55:23.820331Z","iopub.status.idle":"2022-11-23T06:55:24.034926Z","shell.execute_reply.started":"2022-11-23T06:55:23.820294Z","shell.execute_reply":"2022-11-23T06:55:24.033881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img_dir_path = os.path.join(config.base_input_path, \"test_images\")","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:24.036464Z","iopub.execute_input":"2022-11-23T06:55:24.036833Z","iopub.status.idle":"2022-11-23T06:55:24.041938Z","shell.execute_reply.started":"2022-11-23T06:55:24.036798Z","shell.execute_reply":"2022-11-23T06:55:24.040914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datasets = CassavaDataset(\n    annotation_path=train_path,\n    img_dir_path=train_img_dir_path,\n    img_transforms=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n    ])\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:24.04357Z","iopub.execute_input":"2022-11-23T06:55:24.043917Z","iopub.status.idle":"2022-11-23T06:55:24.068704Z","shell.execute_reply.started":"2022-11-23T06:55:24.043882Z","shell.execute_reply":"2022-11-23T06:55:24.067852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(\n    train_datasets,\n    batch_size=config.batch_size,\n    shuffle=True,\n    num_workers=config.num_workers\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:24.070503Z","iopub.execute_input":"2022-11-23T06:55:24.070759Z","iopub.status.idle":"2022-11-23T06:55:24.07785Z","shell.execute_reply.started":"2022-11-23T06:55:24.070735Z","shell.execute_reply":"2022-11-23T06:55:24.077024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\nmodel = CassavaNetwork()\nmodel = model.to(torch.device(\"cuda\"))\nmodel = nn.DataParallel(model)\n\noptimizer = optim.Adam(model.parameters(), lr=config.lr)\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\nloss_function = nn.CrossEntropyLoss()\n\nactivate_function = nn.Softmax(dim=1)\n\ntrainer = Trainer(\n    model,\n    optimizer,\n    scheduler,\n    loss_function,\n    dataloader,\n)\nclassifier = Classifier(\n    model,\n    activate_function,\n    dataloader,\n    phase=\"train\",\n    phase_input=ClassifierTrainInput(),\n)\n\nfor epoch in tqdm(range(config.n_epochs)):\n    epoch += 1\n    train_out = trainer.advance()\n    print(f\"epoch: {epoch}, train loss: {train_out.loss}\")\n    infer_out = classifier.infer()\n    print(f\"epoch: {epoch}, train acc: {infer_out.acc}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-23T06:55:24.080461Z","iopub.execute_input":"2022-11-23T06:55:24.080886Z"},"trusted":true},"execution_count":null,"outputs":[]}]}